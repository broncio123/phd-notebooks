{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODEL GENERATION STAGES**\n",
    "\n",
    "For all mutant sequences\n",
    "\n",
    "* Docking with Conformational classification (GEOMETRY ANALYSIS)\n",
    "* Simulation of Dynamics (XXMD)\n",
    "    * EMMD\n",
    "    * PRMD\n",
    "    * URMD\n",
    "\n",
    "**INTERACTIONS ANALYSIS**\n",
    "\n",
    "* Generate DB od Interactions per modeling stage\n",
    "* Gather all DBs and determine Super-Base Interchain Interactions\n",
    "* Interaction decomposition per model (mutant, conformation:XXMD-simulation:frame, model name)\n",
    "* Dimensionality reduction (Filter out meanningless base interactions)\n",
    "* Statistics and Comparison between *Model Generation Stages* for all mutants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WAITING FOR SIMS WITH MISSING RESIDUES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTES*\n",
    "\n",
    "* Perform Geometry-Interactions Analysis simulatiniously to avoid DB id-equivalence\n",
    "* Tagging per _Model Generation Stage_\n",
    "\n",
    "> <span style=\"color:blue\">None</span> : For unclassified data\n",
    "\n",
    "> <span style=\"color:blue\">ConformationN</span> : For conformationally classified data\n",
    "\n",
    "> <span style=\"color:blue\">ConformationN:XXMD:Protein_n</span> : For conformationally classified data, after XXMD stage, for Protein frame `n`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages used:\n",
    "\n",
    "pysftp\n",
    "fabric\n",
    "pydispatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MD stages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series of MD stages\n",
    "* **Preparation** \n",
    "\n",
    ">This initial stage eoncompasses several substages such as 1) *MD setup* (of essential GROMACS files), 2) *embedding* (of `Protein` in `POPC` bilayer), and 3) re-solvation (with ice-water). Protocols are available for all \n",
    "of these. See *Section X*.\n",
    "\n",
    "* **Energy-Minimization MD** (EMMD)\n",
    "\n",
    ">Minimisation of the `System`'s total energy up to the nearest found local minima, via steepest descent algorithm.\n",
    "\n",
    "* **Position-Restrained MD** (PRMD)\n",
    "\n",
    ">Position restrain of `Protein` backbone-atoms (`N`, `C`, `O`) for NPT-equilibration of the `System`.\n",
    "\n",
    "* **Unrestrained MD** (URMD)\n",
    "\n",
    ">Standard MD production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence of paired-stages\n",
    "\n",
    "```bash\n",
    "prep, embed\n",
    "embed, emmd\n",
    "emmd, prmd,\n",
    "prmd, urmd\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check previous, and refine list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T16:34:34.604573Z",
     "start_time": "2019-01-05T16:34:34.592808Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "mpmodeling_dir = '/home/ba13026/mpmodeling/'\n",
    "\n",
    "engines = {\n",
    "    'pre-md': {\n",
    "            'setup': mpmodeling_dir+'gmx_protocols/prepare_protein_com.sh',\n",
    "            'embed': mpmodeling_dir+'protocols/gmx_protocols/embed_protein.sh',\n",
    "            'resolvate': mpmodeling_dir+'protocols/gmx_protocols/resolvate2.sh'\n",
    "        },\n",
    "    'xxmd' : {\n",
    "        # Create initiation files\n",
    "        'prepare': '',\n",
    "        # Use templates to make submission files and submit jobs to one or both clusters\n",
    "        'submit' : '',\n",
    "        'manage' : ''\n",
    "        },\n",
    "    'analysis': {\n",
    "        #Geometry-Interaction DB# \n",
    "        'get-frames' : '',\n",
    "        'setup-db' : '',\n",
    "        'fill-db' : '',\n",
    "        'make-nb' : '' \n",
    "        },\n",
    "    'backup' : {}\n",
    "}\n",
    "\n",
    "files4check = {\n",
    "    'setup': {\n",
    "        'in':['confout_pep'], \n",
    "        'out': ['for_embedding']\n",
    "    },\n",
    "    'embed': {\n",
    "        'in':['for_embedding'] ,\n",
    "        'out':['confout']\n",
    "    },\n",
    "    'resolvate': {\n",
    "        'in':['confout'],\n",
    "        'out':['ionise']\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-cluster Job Management System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The system relies on a **master-slave** communication model, where one single clusters is in charge of preparing all run files  per model (GROMACS `.tpr` initiation files; cluster independent) and all relevant submission files (`slurm` files; cluster dependent: resources and expected job performance).\n",
    "\n",
    "The workflow below will be described assuming two clusters only (although the overall logic can be extended to more than two clusters). Plus, all clusters are assumed to be accessed via an SSH protocol by a common user (although  extensible to two users), and all jobs are assumed to be either `cpu` or `gpu`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up: Cluster access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  Decide identity of master and slave clusters: `C_master` and `C_slave`,\n",
    "2.  By default, the `local` and `remote` clusters will correspond to the **master** and **slave** clusters, respectively,\n",
    "3.  Set up *working directories* (`workdir`) on both clusters, with a **common basename**, e.g., `mydir`, at some relevant path on each cluster.\n",
    "4.  Define `C_master` and `C_slave` as objects according to the Python class `Cluster`, with relevant instances:\n",
    "\n",
    ">```python\n",
    "class Cluster(object):\n",
    "    def __init__(self):\n",
    "        self.type = '' # Either 'local' or 'remote'\n",
    "        self.name = '' # Cluster name, e.g., 'bluegem.acrc.bris.ac.uk'\n",
    "        self.user = '' # Username, e.g., 'ba13026'\n",
    "        self.pwd = '' # SSH Password\n",
    "        self.workdir = '' # Absolute path: /path_to_dir_in_cluster/mydir/\n",
    "        self.slurm_cpu_template = '' # Can be defined either as concatenated strings or a method\n",
    "        self.slurm_gpu_template = '' # Same as above\n",
    "```\n",
    "\n",
    "saving all Python lines in a file named `ClusterComm_setup.py`\n",
    "\n",
    "Once ready, the function `transfer` defined within `ClusterComm_methods.py`, should be able to easily exchange files between `C_master` and `C_slave`, either *sequentially* or in *parallel* as shown in **Subsec X**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up: I/O Folder Tree Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For unambiguous allocation of MD data per classified docked model we use a *tree-structure* of folders within `mydir`, which must be identical within both cluster working directories; according to the list of classification tags associated to each  PDB model,\n",
    "\n",
    "> Model classification tags: ( `mutant`, `group`, `name` )\n",
    "\n",
    "*Recall*: Here, `mutant` corresponds to an element in a list of sequence names (`str`), whereas `group`, can be defined as `unclassified`, `conformation1`, `conformation1:md`, for instance; and `name` is the name of the model as docking output, usually featuring a unique number.\n",
    "\n",
    "The pseudo-code below illustrates how to create a folder-tree structure according to the intrinsic hierarchy of the classification tags via nested loops\n",
    "\n",
    "\n",
    "```python\n",
    "for i in range(len( mutant_seqnames )):\n",
    "    mutant = mutant_seqnames[i]\n",
    "    # Name of first-level dir\n",
    "    mutant_dir = Cluster.workir + mutant\n",
    "    # Then, make this dir\n",
    "    \n",
    "    for j in range(len( defined_groups[mutant] )):\n",
    "        group = defined_groups[mutant][j]\n",
    "        # Name of second-level dir\n",
    "        group_dir = mutant_dir + '/' + group\n",
    "        # Then, make this dir\n",
    "        \n",
    "        for k in range(len( PDBs[group] )):\n",
    "            pdb_name = PDBs[group][k]\n",
    "            # Name of third-level dir\n",
    "            model_dir = group_dir + '/' + pdb_name\n",
    "            # Then, make this dir\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, by using a list of paths to each individual model directory (*leaf-folder*), it is clear that we can use our MD Python scripts for preparation or submission to any cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remote cluster manipulation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File exchange between clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inter-cluster communication for job queueing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pydispatch import dispatcher\n",
    "SIGNAL = 'my-first-signal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handle_event( sender ):\n",
    "    \"\"\"Simple event handler\"\"\"\n",
    "    print('Signal was sent by', sender)\n",
    "\n",
    "dispatcher.connect( handle_event, signal=SIGNAL, sender=dispatcher.Any )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_sender = object()\n",
    "second_sender = {}\n",
    "\n",
    "def main( ):\n",
    "    dispatcher.send( signal=SIGNAL, sender=first_sender )\n",
    "    dispatcher.send( signal=SIGNAL, sender=second_sender )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job-tracker and manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get list of model tags, per job name for submission.\n",
    "\n",
    "Say job \n",
    "\n",
    "`name` = `md_100ns`\n",
    "\n",
    "and we get the list of all models for which PRMD stage has been finalised. \n",
    "\n",
    "Once the list is given, determine `queueing state`, per model (`model_id`) on each cluster: \n",
    "\n",
    "* `q_master(model_id)`\n",
    "* `q_slave(model_id)`\n",
    "\n",
    "A queueing state per model can take the following values per cluster:\n",
    "\n",
    "* Running : `R` \n",
    "* Pending: `PD`\n",
    "* Done: `D` \n",
    "* Filed:  `F` \n",
    "* Not Submitted: `NS`\n",
    "\n",
    "Transitional states: `NS`, `PD`, `R`, and `F` \n",
    "\n",
    "For a transition from one state to another to happen, an `action` is usually performed per model, as listed below:\n",
    "\n",
    "* <span style=\"color:red\">Submission</span>: `NS` to `PD`\n",
    "* Execution: `PD` to `R`\n",
    "* Completion: `R` to `D`\n",
    "* Queueing Failure: `PD` to `F`\n",
    "* Execution failure: `R` to `F`\n",
    "* <span style=\"color:red\">Resubmission</span>: `F` to `PD` (up to a number of trials)\n",
    "\n",
    "Note that some `actions` are simply performed automatically by the cluster, whereas for others, we need a script to be executed by either the master or the slave cluster. The actions in red are the only ones that need a manager.\n",
    "\n",
    "Stationary states: `D`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Inter-Cluster Job Management** will consist of controlling two actions\n",
    "\n",
    "* _Job Queueing_: Submissions and  Resubmissions\n",
    "\n",
    "* _Job Cancellation_: Forced Execution-failure and Queueing-failure \n",
    "\n",
    "\n",
    "Inter-cluster interaction rules (<span style=\"color:blue\">HERE'S WHERE THE MANAGEMENT ACTUALLY COMES INTO PLAY</span>) on any of the clusters, either `local` or `remote` ones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rules for Inter-Cluster Job Management**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Either use: `sbatch`, `scancel`, or `None`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _Job Queueing_\n",
    "\n",
    "Given a model, with `model_id`\n",
    "\n",
    "\n",
    "IF\n",
    "\n",
    "`q_X(model_id) in ['NS','F']`, for `X = local` and `remote`\n",
    "\n",
    "THEN\n",
    "\n",
    "Submit job = 1 , for `Cluster_local` and `Cluster_remote`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code:\n",
    "\n",
    "```python\n",
    "####################################\n",
    "import numpy\n",
    "\n",
    "tSS = ['NS','F'] \n",
    "f = lambda x: x in tSS \n",
    "\n",
    "q_X = {} \n",
    "for ctype in ['local', 'remote']:\n",
    "    Cluster_X = Clusters[ctype]\n",
    "    q_X[ctype] = get_submission_state(model_id, Cluster_X)\n",
    "    \n",
    "if all(map(f, q_X.values())) == True:\n",
    "    for ctype in ['local', 'remote']:\n",
    "        Cluster_X = Clusters[ctype]\n",
    "        submit2cluster(model_id, Cluster_X)\n",
    "####################################\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _Job Cancellation_\n",
    "\n",
    "IF \n",
    "\n",
    "`q_X(model_id) in ['R','D']`, for `X = local` and `remote`\n",
    "\n",
    "and \n",
    "\n",
    "`q_X(model_id) in ['PD', 'F', 'NS']`, for `Y != X`\n",
    "\n",
    "THEN \n",
    "\n",
    "KILL JOB on `Cluster_Y`, if `q_X(model_id) == 'PD'`\n",
    "\n",
    "DO NOTHING, if `q_X(model_id) in ['F','NS']`\n",
    "\n",
    "\n",
    "ELSE\n",
    "\n",
    "\n",
    "`q_X(model_id) == ['R', 'D', '']` for some `X = local` or `remote`\n",
    "\n",
    "Submit job = 0, for both clusters \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code:\n",
    "\n",
    "```python\n",
    "####################################\n",
    "import numpy\n",
    "\n",
    "tSS0 = ['R','D']\n",
    "tSS1 = ['PD', 'F', 'NS']\n",
    "\n",
    "f0 = lambda x: x in tSS0\n",
    "f1 = lambda x: x in tSS1\n",
    "\n",
    "q_X = {} \n",
    "for ctype in ['local', 'remote']:\n",
    "    Cluster_X = Clusters[ctype]\n",
    "    q_X[ctype] = get_submission_state(model_id, Cluster_X)\n",
    "\n",
    "if any(map(f0, q_X.values())) and any(map(f1, q_X.values())):\n",
    "    for ctype in ['local', 'remote']:\n",
    "        Cluster_X = Clusters[ctype]\n",
    "        if q_X[ctype] == 'PD':\n",
    "            kill_job(model_id, Cluster_X)\n",
    "####################################\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T09:25:42.951373Z",
     "start_time": "2019-01-10T09:25:42.941296Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Import modules from folder\n",
    "modules_path = \"/home/ba13026/mpmodeling/protocols/\"\n",
    "if modules_path not in sys.path:\n",
    "    sys.path.append(modules_path)\n",
    "\n",
    "def kill_job():\n",
    "    print(\"I killed job\")\n",
    "\n",
    "def submit2cluster():\n",
    "    print(\"I submitted jobs to clusters\")\n",
    "\n",
    "def get_submission_state():\n",
    "    SS = {'local': 'R', 'remote':'PD'}\n",
    "    return SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T09:30:22.004693Z",
     "start_time": "2019-01-10T09:30:22.001488Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cluster_transfer import BG, BC4\n",
    "\n",
    "SS = get_submission_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T09:26:53.880815Z",
     "start_time": "2019-01-10T09:26:53.878025Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CLUSTERS = [BG, BC4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T09:27:42.048648Z",
     "start_time": "2019-01-10T09:27:42.043047Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test Submission States\n",
    "tSS = ['NS','F'] \n",
    "tSS0 = ['R','D']\n",
    "tSS1 = ['PD', 'F', 'NS']\n",
    "# Test functions\n",
    "f = lambda x: x in tSS\n",
    "f0 = lambda x: x in tSS0\n",
    "f1 = lambda x: x in tSS1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T09:30:53.068526Z",
     "start_time": "2019-01-10T09:30:53.064655Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['R', 'PD'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SS.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T14:07:34.466651Z",
     "start_time": "2019-01-10T14:07:34.090248Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(map(f0, SS.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMBINED CODE**\n",
    "\n",
    "```python\n",
    "####################################\n",
    "import sys\n",
    "import os\n",
    "import numpy\n",
    "import concurrent.futures\n",
    "from cluster_transfer import BG, BC4\n",
    "from some_lib import get_submission_state, submit2cluster, kill_job \n",
    "\n",
    "CLUSTERS = [BG, BC4]\n",
    "\n",
    "# Test Submission States\n",
    "tSS = ['NS','F'] \n",
    "tSS0 = ['R','D']\n",
    "tSS1 = ['PD', 'F', 'NS']\n",
    "# Test functions\n",
    "f = lambda x: x in tSS\n",
    "f0 = lambda x: x in tSS0\n",
    "f1 = lambda x: x in tSS1\n",
    "\n",
    "JobsDB = 'path/jobs.db'\n",
    "job_name = 'md_100ns'\n",
    "\n",
    "def manage_submission(model_id):\n",
    "    # Get all cluster submission states\n",
    "    SS = {} \n",
    "    for Cluster in CLUSTERS:\n",
    "        SS[Cluster.type] = get_submission_state(model_id, job_name, JobsDB, Cluster)\n",
    "        \n",
    "    # Job Queueing: Submit/Resubmit\n",
    "    if all(map(f, SS.values())) == True:\n",
    "        for Cluster in CLUSTERS:\n",
    "            submit2cluster(model_id, job_name, JobsDB, Cluster)\n",
    "\n",
    "    # Job Cancellation: Force Running/Queueing failure\n",
    "    if any(map(f0, SS.values())) and any(map(f1, SS.values())):\n",
    "        for Cluster in CLUSTERS:\n",
    "            if SS[Cluster.type] == 'PD':\n",
    "                kill_job(model_id, job_name, JobsDB, Cluster)\n",
    "   \n",
    "def main():\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers = n_cpus) as executor:\n",
    "        executor.map(func, param_list)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    n_cpus = sys.argv[1]\n",
    "    param_list = model_IDS\n",
    "    func = manage_submission\n",
    "    main()\n",
    "             \n",
    "####################################\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">CONTINUE FROM HERE</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work on libraries for `get_submission_state, submit2cluster, kill_job`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T14:45:32.897306Z",
     "start_time": "2019-01-10T14:45:32.838651Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "modules_path = \"/home/ba13026/mpmodeling/protocols/\"\n",
    "if modules_path not in sys.path:\n",
    "    sys.path.append(modules_path)\n",
    "\n",
    "# from setup_db_JobManager  import Tags, Jobs, Base\n",
    "from cluster_transfer import BG, BC4\n",
    "\n",
    "import importlib\n",
    "import setup_db_JobManager\n",
    "importlib.reload(setup_db_JobManager)\n",
    "\n",
    "dbfile = BG.workdir+'jobs.db'\n",
    "engine = create_engine('sqlite:///'+dbfile)\n",
    "setup_db_JobManager.Base.metadata.bind = engine\n",
    "DBSession = sessionmaker()\n",
    "DBSession.bind = engine\n",
    "session = DBSession()\n",
    "\n",
    "# JobsDB = dbfile\n",
    "\n",
    "\n",
    "job_name = 'md_100ns'\n",
    "queue = 'local'\n",
    "state = 'PD'\n",
    "\n",
    "model_ids = [x[0] for x in session.query(setup_db_JobManager.Jobs.id).filter_by(\n",
    "                state = state,\n",
    "                queue = queue,\n",
    "                job_name = job_name\n",
    "            ).all()]\n",
    "\n",
    "# filtered_tags = []\n",
    "# for id in model_ids:\n",
    "#     x = session.query(\n",
    "#             setup_db_JobManager.Tags.mutant,\n",
    "#             setup_db_JobManager.Tags.group,\n",
    "#             setup_db_JobManager.Tags.pdb_name\n",
    "#         ).filter_by(id=id).all()\n",
    "#     filtered_tags.append(json.dumps(list(x[0])))\n",
    "\n",
    "# def get_submission_state(model_id, job_name, JobsDB, Cluster):\n",
    "#     pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T14:46:28.196895Z",
     "start_time": "2019-01-10T14:46:28.189441Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PD')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.query(\n",
    "    setup_db_JobManager.Jobs.state\n",
    "    ).filter_by(id = 24).all()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T14:55:34.613323Z",
     "start_time": "2019-01-10T14:55:34.607382Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SS = {}\n",
    "model_jobname_id = 24\n",
    "\n",
    "for Cluster in CLUSTERS:\n",
    "    queue_id, state = session.query(\n",
    "        setup_db_JobManager.Jobs.states\n",
    "        ).filter_by(id = model_jobname_id).all()\n",
    "    \n",
    "    SS[Cluster.type] = {\n",
    "        'job_id': job_id,\n",
    "        'state': state\n",
    "        }\n",
    "    \n",
    "SS = {\n",
    "    'local': [queue_id, state]\n",
    "    'remote': [queue_id, state]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">ISSUE</span>**\n",
    "\n",
    "\n",
    "IF MANAGER IS LAUNCHED EVERY 15 SECS, THEN THINKABOUT WHAT TO DO WITH CONSTANTLY FAILING JOBS.\n",
    "ALSO, THINK THAT SUBMIT AND CANCEL FUNCTIONS SHOULD UPDATE THE DATABASE OF JOB STATES.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Future imporvement: \n",
    "\n",
    "Prority for CPU or GPU jobs per cluster can be defined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to determine queueing states**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different states can be determined either 1) using `scontrol` alone, knowing the `job_id` beforehand (stored in DB), or 2) with any other alternative criteria as indicated below. \n",
    "\n",
    "If `job_id` unkown, then you need to extract them using `squeue` and associating these to each model, on each cluster, and then feeding these into DB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queueing states are:\n",
    "\n",
    "* Running : `R` \n",
    "\n",
    "> Can be determined using `scontrol` if `job_id` on cluster available\n",
    "\n",
    "* Pending: `PD`\n",
    "\n",
    "> Can be determined using `scontrol` if `job_id` on cluster available\n",
    "\n",
    "* Done: `D` \n",
    "\n",
    "> Determined either using `scontrol` if `job_id` on cluster available or just checking presence of expected output files: `name.gro` and NO ERROR MESSAGE\n",
    "\n",
    "* Failed:  `F` \n",
    "\n",
    "> Determined either using `scontrol` if `job_id` on cluster available or just checking presence of expected error output files:  ............. and NO ERROR MESSAGE\n",
    "\n",
    "* Not Submitted: `NS`\n",
    "\n",
    "> Determined either using `scontrol` if `job_id` on cluster available or just checking presence of expected output files: `name.log, .xtc, .edr`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to get `job_id`s per model on a cluster**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Job submitted for first time, then use sbatch to get id and record this in DB\n",
    "* Job already on queue but no job_id recorded in DB. Need to get model_id too (use model tags)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
